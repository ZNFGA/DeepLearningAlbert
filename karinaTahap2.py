# -*- coding: utf-8 -*-
"""Karina.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OwnG_4CczoYkkY7cRvoorRh3OCCHBPL4
"""

!pip install torch torchvision torchinfo scikit-learn pandas matplotlib Pillow tqdm

import os
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # Untuk deterministik di CUDA

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import random

def set_seed(seed=42):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True)

set_seed()

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

from google.colab import drive
drive.mount("/content/drive")

BASE_PATH = "/content/drive/MyDrive/at least I am try/IF25-4041-dataset"
TRAIN_IMG_DIR = os.path.join(BASE_PATH, "train")
TRAIN_CSV_PATH = os.path.join(BASE_PATH, "train.csv")

print(" Train images:", TRAIN_IMG_DIR)
print(" Train CSV   :", TRAIN_CSV_PATH)

train_df = pd.read_csv(TRAIN_CSV_PATH)

LABEL_MAP = {
    'nasi_goreng': 0,
    'rendang': 1,
    'soto_ayam': 2,
    'bakso': 3,
    'gado_gado': 4
}
REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}

image_paths = [os.path.join(TRAIN_IMG_DIR, fname) for fname in train_df['filename']]
labels = [LABEL_MAP[label] for label in train_df['label']]

print(f" Total gambar train: {len(image_paths)}")
print(f" Distribusi label:")
print(pd.Series(train_df['label']).value_counts().to_dict())

class FoodDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        try:
            img = Image.open(self.image_paths[idx])
            if img.mode == 'P' and 'transparency' in img.info:
                img = img.convert('RGBA')
            if img.mode == 'RGBA':
                background = Image.new('RGB', img.size, (255, 255, 255))
                background.paste(img, mask=img.split()[-1])
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading {self.image_paths[idx]}: {e}")
            img = Image.new('RGB', (224, 224))

        label = self.labels[idx]
        if self.transform:
            img = self.transform(img)
        return img, label

train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

print(" Transformasi siap digunakan.")

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
fold_splits = []

print(" Membagi data menjadi 5 fold secara stratified...")
for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):
    fold_splits.append({'train_idx': train_idx, 'val_idx': val_idx})
    print(f"  Fold {fold}: Train={len(train_idx)} | Val={len(val_idx)}")

class ResNetBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResNetBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,
                              stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,
                              stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample

    def forward(self, x):
        identity = x  # Input asli untuk skip connection

        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        # Transform identity jika dimensi berubah
        if self.downsample is not None:
            identity = self.downsample(identity)

        # üîë RESIDUAL CONNECTION: tambahkan identity ke output
        out += identity

        out = F.relu(out)
        return out

class ResNet34(nn.Module):
    def __init__(self, num_classes=5):
        super(ResNet34, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        self.stage1 = self._make_stage(64, 64, 3, stride=1)
        self.stage2 = self._make_stage(64, 128, 4, stride=2)
        self.stage3 = self._make_stage(128, 256, 6, stride=2)
        self.stage4 = self._make_stage(256, 512, 3, stride=2)

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)
        self._initialize_weights()

    def _make_stage(self, in_channels, out_channels, num_blocks, stride):
        downsample = None
        if stride != 1 or in_channels != out_channels:
            downsample = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels),
            )
        layers = [ResNetBlock(in_channels, out_channels, stride, downsample)]
        for _ in range(1, num_blocks):
            layers.append(ResNetBlock(out_channels, out_channels))
        return nn.Sequential(*layers)

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.maxpool(x)

        x = self.stage1(x)
        x = self.stage2(x)
        x = self.stage3(x)
        x = self.stage4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x

def get_model():
    """Mengembalikan model ResNet-34 (from scratch)."""
    return ResNet34(num_classes=5)

print("\n" + "="*60)
print("MENGECEK ARSITEKTUR RESNET-34")
print("="*60)
model_dummy = get_model()
try:
    from torchinfo import summary
    summary(model_dummy, input_size=(1, 3, 224, 224), device='cpu')
except ImportError:
    print("torchinfo tidak terinstal. Lewati summary.")
    with torch.no_grad():
        test_out = model_dummy(torch.randn(1, 3, 224, 224))
        print(f"Output shape: {test_out.shape}")

from tqdm import tqdm

def train_one_epoch(model, dataloader, criterion, optimizer, device):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in tqdm(dataloader, desc="Training", leave=False):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        total_loss += loss.item()
        _, preds = outputs.max(1)
        correct += preds.eq(labels).sum().item()
        total += labels.size(0)
    return total_loss / len(dataloader), correct / total

def validate(model, dataloader, criterion, device):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for images, labels in tqdm(dataloader, desc="Validating", leave=False):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = outputs.max(1)
            correct += preds.eq(labels).sum().item()
            total += labels.size(0)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    f1 = f1_score(all_labels, all_preds, average='macro')
    return total_loss / len(dataloader), correct / total, f1, all_preds, all_labels

criterion = nn.CrossEntropyLoss()

print("\nüöÄ MULAI TRAINING RESNET-34 (DENGAN RESIDUAL) - 5 FOLD")

best_fold = -1
best_f1 = 0
all_fold_results = []

# üîß HYPERPARAMETER IDENTIK DENGAN TAHAP 1
EPOCHS = 50
BATCH_SIZE = 32
LR = 0.01
MOMENTUM = 0.9
WEIGHT_DECAY = 1e-4

for fold in range(5):
    print(f"\n{'='*60}")
    print(f" FOLD {fold+1}/5 ‚Äî RESNET-34 (DENGAN RESIDUAL)")
    print('='*60)

    # Dataset (sama seperti Tahap 1)
    train_dataset = FoodDataset(
        [image_paths[i] for i in fold_splits[fold]['train_idx']],
        [labels[i] for i in fold_splits[fold]['train_idx']],
        transform=train_transform
    )
    val_dataset = FoodDataset(
        [image_paths[i] for i in fold_splits[fold]['val_idx']],
        [labels[i] for i in fold_splits[fold]['val_idx']],
        transform=val_transform
    )

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,
                              num_workers=2, worker_init_fn=lambda x: set_seed(42))
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,
                            num_workers=2, worker_init_fn=lambda x: set_seed(42))

    # Model
    model = get_model().to(device)

    # Optimizer & Scheduler (sama seperti Tahap 1)
    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)

    best_val_f1 = 0
    patience = 5
    counter = 0

    # Training Loop
    for epoch in range(EPOCHS):
        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)
        val_loss, val_acc, val_f1, _, _ = validate(model, val_loader, criterion, device)
        scheduler.step()

        print(f"  Epoch {epoch+1}/{EPOCHS} | "
              f"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}")

        if val_f1 > best_val_f1:
            best_val_f1 = val_f1
            counter = 0
            torch.save(model.state_dict(), f'resnet34_fold{fold}_best.pth')
        else:
            counter += 1
            if counter >= patience:
                print("    ‚è∏Ô∏è  Early stopping!")
                break

    all_fold_results.append({'fold': fold, 'best_val_f1': best_val_f1})
    if best_val_f1 > best_f1:
        best_f1 = best_val_f1
        best_fold = fold

print(f"\nüèÜ FOLD TERBAIK: Fold {best_fold} dengan F1 = {best_f1:.4f}")
torch.save(torch.load(f'resnet34_fold{best_fold}_best.pth'), 'resnet34_best.pth')
print("‚úÖ Model ResNet-34 terbaik disimpan sebagai 'resnet34_best.pth'")

model = get_model().to(device)
model.load_state_dict(torch.load('resnet34_best.pth'))
model.eval()

val_dataset = FoodDataset(
    [image_paths[i] for i in fold_splits[best_fold]['val_idx']],
    [labels[i] for i in fold_splits[best_fold]['val_idx']],
    transform=val_transform
)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

_, _, _, all_preds, all_labels = validate(model, val_loader, criterion, device)

# Laporan klasifikasi
print("\nüìä === METRIK PER-KELAS (RESNET-34) ===")
target_names = list(LABEL_MAP.keys())
print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8,6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix - ResNet-34 (Dengan Residual)')
plt.colorbar()
tick_marks = np.arange(len(target_names))
plt.xticks(tick_marks, target_names, rotation=45)
plt.yticks(tick_marks, target_names)
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.savefig('confusion_matrix_resnet34.png', dpi=150)
plt.show()

print("‚úÖ Confusion matrix disimpan ke 'confusion_matrix_resnet34.png'")
print("‚úÖ SELESAI TAHAP 2! SIAP UNTUK PERBANDINGAN DAN TAHAP 3.")



